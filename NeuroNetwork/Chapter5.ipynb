{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多入单出的单层神经网络 - 多变量线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 多样本单特征值计算：\n",
    "- dataReader：shuffle()\n",
    "- 前向计算环节:  def __forwardBatch(self, batch_x):\n",
    "- 损失函数： \n",
    "        Z = self.__forwardBatch(X)\n",
    "        LOSS = (Z - Y)**2\n",
    "        loss = LOSS.sum()/m/2\n",
    "- 反向传播：\n",
    "- 训练环节："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把预测数据放在训练数据中先做归一化，再预测，就不需要还原权重矩阵了\n",
    "- 归一化\n",
    "  - 训练样本数据归一化 reader.NormalizeX()\n",
    "  - 用于预测数据（即特征值）的归一化：reader.NormalizePredicateData()\n",
    "- 此时loss、w、b的值都没有归一化，不符合神经网络的概率计算优点  \n",
    "数据结果可视化：def ShowResult(net, reader):  \n",
    "**可视化不工作？**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import LogNorm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"ch05.npz\"\n",
    "\n",
    "def TargetFunction(x1, x2):\n",
    "    w1, w2, b = 2, 5, 10\n",
    "    return w1 * (20 - x1) + w2 * x2 + b\n",
    "\n",
    "\n",
    "def CreateSampleData(m):\n",
    "    file = Path(file_name)\n",
    "    if file.exists():\n",
    "        data = np.load(file)\n",
    "        X = data[\"data\"]\n",
    "        Y = data[\"label\"]\n",
    "    else:\n",
    "        X = np.zeros((m, 2))\n",
    "        # radius [2,20]\n",
    "        X[:, 0:1] = (np.random.random(1000) * 20 + 2).reshape(1000, 1)\n",
    "        # [40,120] square\n",
    "        X[:, 1:2] = np.random.randint(40, 120, (m, 1))\n",
    "        Y = TargetFunction(X[:, 0:1], X[:, 1:2])\n",
    "        Noise = np.random.randint(1, 100, (m, 1)) - 50\n",
    "        Y = Y + Noise\n",
    "        np.savez(file_name, data=X, label=Y)\n",
    "    return X, Y\n",
    "\n",
    "X, Y = CreateSampleData(1000)\n",
    "\n",
    "print(X[:, 0].max())\n",
    "print(X[:, 0].min())\n",
    "print(X[:, 0].mean())\n",
    "print(X[:, 1].max())\n",
    "print(X[:, 1].min())\n",
    "print(X[:, 1].mean())\n",
    "print(Y.max())\n",
    "print(Y.min())\n",
    "print(Y.mean())\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.scatter(X[:, 0], X[:, 1], Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters(object):\n",
    "    def __init__(\n",
    "        self, input_size, output_size, eta=0.1, max_epoch=1000, batch_size=5, eps=0.1,\n",
    "    ):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.eta = eta\n",
    "        self.max_epoch = max_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.eps = eps\n",
    "        self.NetType = net_type\n",
    "\n",
    "    def toString(self):\n",
    "        title = str.format(\"bz:{0},eta:{1}\", self.batch_size, self.eta)\n",
    "        return title\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingHistory_1_0(object):\n",
    "    def __init__(self):\n",
    "        self.iteration = []\n",
    "        self.loss_history = []\n",
    "\n",
    "    def AddLossHistory(self, iteration, loss):\n",
    "        self.iteration.append(iteration)\n",
    "        self.loss_history.append(loss)\n",
    "\n",
    "    def ShowLossHistory(self, hp, xmin=None, xmax=None, ymin=None, ymax=None):\n",
    "        plt.plot(self.iteration, self.loss_history)\n",
    "        title = hp.toString()\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        if xmin != None and ymin != None:\n",
    "            plt.axis([xmin, xmax, ymin, ymax])\n",
    "        plt.show()\n",
    "        return title\n",
    "\n",
    "    def GetLast(self):\n",
    "        count = len(self.loss_history)\n",
    "        return self.loss_history[count-1], self.w_history[count-1], self.b_history[count-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(object):\n",
    "    def __init__(self, hp):\n",
    "        self.hp = hp\n",
    "        self.W = np.zeros((self.hp.input_size, self.hp.output_size))#权重矩阵由神经网络输入输出个数决定\n",
    "        self.B = np.zeros((1, self.hp.output_size))\n",
    "# 多样本计算\n",
    "    def __forwardBatch(self, batch_x):\n",
    "        Z = np.dot(batch_x, self.W) + self.B\n",
    "        return Z\n",
    "\n",
    "    def __backwardBatch(self, batch_x, batch_y, batch_z):\n",
    "        m = batch_x.shape[0]\n",
    "        dZ = batch_z - batch_y\n",
    "        dB = dZ.sum(axis=0, keepdims=True)/m\n",
    "        dW = np.dot(batch_x.T, dZ)/m\n",
    "        return dW, dB\n",
    "\n",
    "    def __update(self, dW, dB):\n",
    "        self.W = self.W - self.hp.eta * dW\n",
    "        self.B = self.B - self.hp.eta * dB\n",
    "\n",
    "    def inference(self, x):\n",
    "        return self.__forwardBatch(x)\n",
    "    def __checkLoss(self, dataReader):#多样本损失函数计算\n",
    "        X,Y = dataReader.GetWholeTrainSamples()\n",
    "        m = X.shape[0]\n",
    "        Z = self.__forwardBatch(X)\n",
    "        LOSS = (Z - Y)**2\n",
    "        loss = LOSS.sum()/m/2\n",
    "        return loss\n",
    "    \n",
    " \n",
    "#训练\n",
    "    def train(self, dataReader, checkpoint):\n",
    "        # calculate loss to decide the stop condition\n",
    "        loss_history = TrainingHistory_1_0()\n",
    "        loss = 10\n",
    "        if self.hp.batch_size == -1:\n",
    "            self.hp.batch_size = dataReader.num_train\n",
    "        max_iteration = math.ceil(dataReader.num_train / self.hp.batch_size)\n",
    "        checkpoint_iteration = (int)(max_iteration * checkpoint)\n",
    "\n",
    "        for epoch in range(self.hp.max_epoch):\n",
    "            print(\"epoch=%d\" %epoch)\n",
    "            dataReader.Shuffle()\n",
    "            for iteration in range(max_iteration):\n",
    "                # get x and y value for one sample\n",
    "                batch_x, batch_y = dataReader.GetBatchTrainSamples(self.hp.batch_size, iteration)\n",
    "                # get z from x,y\n",
    "                batch_z = self.__forwardBatch(batch_x)\n",
    "                # calculate gradient of w and b\n",
    "                dW, dB = self.__backwardBatch(batch_x, batch_y, batch_z)\n",
    "                # update w,b\n",
    "                self.__update(dW, dB)\n",
    "\n",
    "                total_iteration = epoch * max_iteration + iteration\n",
    "                if (total_iteration+1) % checkpoint_iteration == 0:\n",
    "                    loss = self.__checkLoss(dataReader)\n",
    "                    print(epoch, iteration, loss, self.W, self.B)\n",
    "                    loss_history.AddLossHistory(epoch*max_iteration+iteration, loss)\n",
    "                    if loss < self.hp.eps:\n",
    "                        break\n",
    "                    #end if\n",
    "                #end if\n",
    "            # end for\n",
    "            if loss < self.hp.eps:\n",
    "                break\n",
    "        # end for\n",
    "        loss_history.ShowLossHistory(self.hp)\n",
    "        print(\"W=\", self.W)\n",
    "        print(\"B=\", self.B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataReader(object):\n",
    "    def __init__(self, data_file):\n",
    "        self.train_file_name = data_file\n",
    "        self.num_train = 0\n",
    "        self.XTrain = None\n",
    "        self.YTrain = None\n",
    "        self.X_norm=None\n",
    "        self.XRAW = None    # raw x\n",
    "        self.YRaw = None    # raw y\n",
    "    #样本随机化\n",
    "    def Shuffle(self):\n",
    "        seed = np.random.randint(0,100)\n",
    "        np.random.seed(seed)\n",
    "        XP = np.random.permutation(self.XTrain)\n",
    "        np.random.seed(seed)\n",
    "        YP = np.random.permutation(self.YTrain)\n",
    "        self.XTrain = XP\n",
    "        self.YTrain = YP\n",
    "    # read data from file\n",
    "    def ReadData(self):\n",
    "        train_file = Path(self.train_file_name)\n",
    "        if train_file.exists():\n",
    "            data = np.load(self.train_file_name)\n",
    "            self.XRAW = data[\"data\"]\n",
    "            self.YRAW = data[\"label\"]\n",
    "            self.num_train = self.XRAW.shape[0]\n",
    "            self.XTrain = self.XRAW\n",
    "            self.YTrain = self.YRAW\n",
    "        else:\n",
    "            raise Exception(\"Cannot find train file!!!\")\n",
    "        # end if\n",
    "\n",
    "    # get batch training data\n",
    "    def GetSingleTrainSample(self, iteration):\n",
    "        x = self.XTrain[iteration]\n",
    "        y = self.YTrain[iteration]\n",
    "        return x, y\n",
    "        \n",
    "    def GetBatchTrainSamples(self, batch_size, iteration):\n",
    "        start = iteration * batch_size\n",
    "        end = start + batch_size\n",
    "        batch_X = self.XTrain[start:end,:]\n",
    "        batch_Y = self.YTrain[start:end,:]\n",
    "        return batch_X, batch_Y\n",
    "\n",
    "    def GetWholeTrainSamples(self):\n",
    "        return self.XTrain, self.YTrain\n",
    "    #X_new矩阵存放归一化后的数据，X_norm存放所有特征值归一化时的最小值和range值\n",
    "    #计算归一化数据，即将X_raw每一列的数据归一化到0-1之间，存放到X_new中\n",
    "    def NormalizeX(self):\n",
    "        X_new = np.zeros(self.XRAW.shape)\n",
    "        num_feature = self.XRAW.shape[1]\n",
    "        self.X_norm = np.zeros((num_feature,2))\n",
    "        # 按列归一化,即所有样本的同一特征值分别做归一化\n",
    "        for i in range(num_feature):\n",
    "            # get one feature from all examples\n",
    "            col_i = self.XRAW[:,i]\n",
    "            max_value = np.max(col_i)\n",
    "            min_value = np.min(col_i)\n",
    "            # min value\n",
    "            self.X_norm[i,0] = min_value \n",
    "            # range value\n",
    "            self.X_norm[i,1] = max_value - min_value \n",
    "            new_col = (col_i - self.X_norm[i,0])/(self.X_norm[i,1])\n",
    "            X_new[:,i] = new_col\n",
    "        #end for\n",
    "        self.XTrain = X_new\n",
    "        return X_new\n",
    "    \n",
    "    def NormalizePredicateData(self, X_raw):\n",
    "        X_new=np.zeros(X_raw.shape)\n",
    "        n=X_raw.shape[1]\n",
    "        for i in range(n):\n",
    "            col_i=X_raw[:,i]\n",
    "            X_new[:,i]=(col_i-self.X_norm[i,0])/self.X_norm[i,1]\n",
    "        return X_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowResult(net, reader):\n",
    "    # draw example points\n",
    "    X,Y = reader.GetWholeTrainSamples()\n",
    "    fig = plt.figure()\n",
    "    ax = Axes3D(fig)\n",
    "    ax.scatter(X[:,0],X[:,1],Y)\n",
    "    # draw fitting surface\n",
    "    p = np.linspace(0,1)\n",
    "    q = np.linspace(0,1)\n",
    "    P,Q = np.meshgrid(p,q)\n",
    "    R = np.hstack((P.ravel().reshape(2500,1), Q.ravel().reshape(2500,1)))\n",
    "    Z = net.inference(R)\n",
    "    Z = Z.reshape(50,50)\n",
    "    ax.plot_surface(P,Q,Z, cmap='rainbow')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#主函数\n",
    "\n",
    "#file_name = \"ch05.npz\"\n",
    "#data\n",
    "reader = SimpleDataReader(file_name)\n",
    "reader.ReadData()\n",
    "reader.NormalizeX()#样本数据归一化\n",
    "#net\n",
    "params = HyperParameters(2, 1, eta=0.1, max_epoch=10, batch_size=1, eps = 1e-5)\n",
    "net = NeuralNet(params)\n",
    "net.train(reader, checkpoint=0.1)\n",
    "# inference\n",
    "x1 = 15\n",
    "x2 = 93\n",
    "x=np.array([x1,x2]).reshape(1,2)\n",
    "x_new=reader.NormalizePredicateData(x)#预测数据归一化\n",
    "print(\"Z=\", net.inference(x_new))#采用归一化的数据进行预测\n",
    "ShowResult(net, reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeruralNetwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
